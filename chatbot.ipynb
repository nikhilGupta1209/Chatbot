{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLAoPqMKVCW1rjSF5w0Acw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhilGupta1209/Chatbot/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTdmoMOGSGLx"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import random\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/nlp_wiki.txt', 'r', errors='ignore')\n",
        "raw = f.read()\n",
        "raw = raw.lower()"
      ],
      "metadata": {
        "id": "0xI4os3-S6c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from nltk.tokenize import punkt\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM2teYeUUGv9",
        "outputId": "18a559f6-c1dc-405e-b10b-c6dd46bec01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens = nltk.sent_tokenize(raw) #converts to list of scentences\n",
        "word_tokens = nltk.word_tokenize(raw) #converts to list of words\n",
        "\n",
        "sentToken = sent_tokens[:4]\n",
        "#print(sentToken)\n",
        "wordToken = word_tokens[:4]\n",
        "#print(wordToken)\n"
      ],
      "metadata": {
        "id": "wh4GVk76T5G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing \n",
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n"
      ],
      "metadata": {
        "id": "X6tIQHGGT89E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Greetings\n",
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\")\n",
        "GREETING_RESPONSES = [\"hi\", \"hey\", \"nods\", \"hi there\", \"hello\", \"I am glad! you are talking to me\"]\n",
        "\n",
        "def greeting(scentence):\n",
        "    \n",
        "    for word in scentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)\n",
        "        "
      ],
      "metadata": {
        "id": "h0hk_tALUqVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "JgaMhQ8iUzTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "    chatbot_response = ''\n",
        "    sent_tokens.append(user_response)\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=\"english\")\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    # print( tfidf)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    \n",
        "    idx = vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf == 0):\n",
        "        chatbot_response = chatbot_response + \"I am sorry! I don't understand you\"\n",
        "        return chatbot_response\n",
        "    \n",
        "    else:\n",
        "        chatbot_response=chatbot_response+sent_tokens[idx]\n",
        "        return chatbot_response\n",
        "    "
      ],
      "metadata": {
        "id": "kbZyuzklU4Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B9CtR-vtWj7N",
        "outputId": "11d91319-57b4-4b3b-879c-549cbe151281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 402)\t0.05374006170465886\n",
            "  (0, 1590)\t0.07767122283406144\n",
            "  (0, 550)\t0.06914677124392811\n",
            "  (0, 1238)\t0.07767122283406144\n",
            "  (0, 1480)\t0.07767122283406144\n",
            "  (0, 250)\t0.13829354248785622\n",
            "  (0, 880)\t0.06400206025814559\n",
            "  (0, 1018)\t0.0776917013099489\n",
            "  (0, 915)\t0.06914677124392811\n",
            "  (0, 627)\t0.0726847383146206\n",
            "  (0, 1240)\t0.06640251078355694\n",
            "  (0, 1254)\t0.06914677124392811\n",
            "  (0, 377)\t0.06640251078355694\n",
            "  (0, 511)\t0.1453694766292412\n",
            "  (0, 681)\t0.1453694766292412\n",
            "  (0, 1162)\t0.11834760441009289\n",
            "  (0, 1489)\t0.1453694766292412\n",
            "  (0, 683)\t0.12452902658958438\n",
            "  (0, 237)\t0.05917380220504644\n",
            "  (0, 749)\t0.06640251078355694\n",
            "  (0, 516)\t0.05670591706174453\n",
            "  (0, 1364)\t0.09750715437043606\n",
            "  (0, 1263)\t0.0726847383146206\n",
            "  (0, 428)\t0.06226451329479219\n",
            "  (0, 1619)\t0.04319498095217037\n",
            "  :\t:\n",
            "  (398, 202)\t0.420727218301625\n",
            "  (398, 1391)\t0.420727218301625\n",
            "  (398, 1491)\t0.3283772159661172\n",
            "  (398, 1573)\t0.3283772159661172\n",
            "  (398, 1577)\t0.31351218580876045\n",
            "  (399, 1047)\t0.38845086414407165\n",
            "  (399, 1524)\t0.38845086414407165\n",
            "  (399, 1259)\t0.38845086414407165\n",
            "  (399, 1616)\t0.38845086414407165\n",
            "  (399, 1611)\t0.36351235860829445\n",
            "  (399, 663)\t0.36351235860829445\n",
            "  (399, 1092)\t0.36351235860829445\n",
            "  (400, 971)\t0.35633199200388743\n",
            "  (400, 664)\t0.35633199200388743\n",
            "  (400, 1433)\t0.35633199200388743\n",
            "  (400, 1591)\t0.35633199200388743\n",
            "  (400, 1614)\t0.35633199200388743\n",
            "  (400, 1613)\t0.35633199200388743\n",
            "  (400, 1155)\t0.35633199200388743\n",
            "  (400, 1187)\t0.33345551475690255\n",
            "  (401, 751)\t1.0\n",
            "  (402, 1039)\t1.0\n",
            "  (403, 1039)\t1.0\n",
            "  (404, 1039)\t1.0\n",
            "  (405, 1039)\t1.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-05011cf07963>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"what is nlp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-5a5e3f7ef10c>\u001b[0m in \u001b[0;36mresponse\u001b[0;34m(user_response)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# vals = cosine_similarity(tfidf[-1], tfidf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mflat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vals' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQCAupiwVJ0N",
        "outputId": "4a8b1d10-485e-4485-af7f-af8f09034d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    flag = True\n",
        "    print(\"Hello, there my name is Aneka. I will answer your queries. If you want to exit, type Bye!\")\n",
        "    while(flag==True):\n",
        "        user_response = input()\n",
        "        user_response = user_response.lower()\n",
        "        if(user_response!='bye'):\n",
        "            if user_response == 'thanks' or user_response == 'thank you':\n",
        "                flag = False\n",
        "                print(\"Aneka: You're welcome!\")\n",
        "            else:\n",
        "                if(greeting(user_response)!=None):\n",
        "                    print(\"Aneka:\" +greeting(user_response))\n",
        "                else:\n",
        "                    print(\"Aneka:\", end='')\n",
        "                    print(response(user_response))\n",
        "                    sent_tokens.remove(user_response)\n",
        "        else:\n",
        "            flag = False\n",
        "            print(\"Aneka: Bye! Have a great time!\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQYP5qm1U7Kc",
        "outputId": "ae700d9f-63cb-4715-b84b-983d381bdb0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, there my name is Aneka. I will answer your queries. If you want to exit, type Bye!\n",
            "hii\n",
            "Aneka:hii\n",
            "what is nlp\n",
            "Aneka:intro to nlp in machine learning\".\n",
            "yes\n",
            "Aneka:I am sorry! I don't understand you\n",
            "natural language\n",
            "Aneka:machine learning of natural language.\n",
            "intr to nlp\n",
            "Aneka:intro to nlp in machine learning\".\n",
            "intro to nlp in machine learning\n",
            "Aneka:intro to nlp in machine learning\".\n",
            "how to Convert chunks of text into more formal representations \n",
            "Aneka:natural-language understanding (nlu)\n",
            "convert chunks of text into more formal representations such as first-order logic structures that are easier for computer programs to manipulate.\n",
            "what is nlg\n",
            "Aneka:[32]\n",
            "natural-language generation (nlg):\n",
            "convert information from computer databases or semantic intents into readable human language.\n",
            "preprocessing in nlp\n",
            "Aneka:despite the popularity of machine learning in nlp research, symbolic methods are still (2020) commonly used:\n",
            "\n",
            "when the amount of training data is insufficient to successfully apply machine learning methods, e.g., for the machine translation of low-resource languages such as provided by the apertium system,\n",
            "for preprocessing in nlp pipelines, e.g., tokenization, or\n",
            "for postprocessing and transforming the output of nlp pipelines, e.g., for knowledge extraction from syntactic parses.\n",
            "founder of nlp\n",
            "Aneka:intro to nlp in machine learning\".\n",
            "what are common nlp task\n",
            "Aneka:common nlp tasks\n",
            "the following is a list of some of the most commonly researched tasks in natural language processing.\n",
            "bye\n",
            "Aneka: Bye! Have a great time!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\\"
      ],
      "metadata": {
        "id": "AdHkBCfCVL1t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}